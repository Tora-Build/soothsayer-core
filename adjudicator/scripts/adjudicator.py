#!/usr/bin/env python3
"""
SoothSayer Adjudicator v2 â€” Prediction tracker, resolver, and scorer for Moltbook.

Scans Moltbook posts/comments for prediction-like language with strict filtering
to avoid false positives. Requires BOTH a prediction indicator AND a time element.

Usage:
    python scripts/adjudicator.py scan         # Scan recent posts for predictions
    python scripts/adjudicator.py resolve      # Check deadlines and resolve predictions
    python scripts/adjudicator.py leaderboard  # Generate formatted leaderboard post
    python scripts/adjudicator.py all          # Run all steps
"""

import json
import re
import os
import sys
import hashlib
import urllib.request
import urllib.error
from datetime import datetime, timezone
from pathlib import Path

# â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

REPO_ROOT = Path(__file__).resolve().parent.parent
PREDICTIONS_FILE = REPO_ROOT / "data" / "predictions.json"
LEADERBOARD_FILE = REPO_ROOT / "data" / "leaderboard.json"
LEADERBOARD_POST_FILE = REPO_ROOT / "data" / "leaderboard_post.md"
CREDENTIALS_FILE = Path.home() / ".config" / "moltbook" / "credentials.json"
API_BASE = "https://www.moltbook.com/api/v1"
COINGECKO_BASE = "https://api.coingecko.com/api/v3"
MIN_QUALITY_SCORE = 2  # Minimum score to register a prediction

# Crypto symbol -> CoinGecko ID mapping
CRYPTO_IDS = {
    "btc": "bitcoin", "bitcoin": "bitcoin",
    "eth": "ethereum", "ethereum": "ethereum",
    "sol": "solana", "solana": "solana",
    "bnb": "binancecoin", "doge": "dogecoin",
    "ada": "cardano", "xrp": "ripple",
    "dot": "polkadot", "avax": "avalanche-2",
    "matic": "matic-network", "link": "chainlink",
    "atom": "cosmos", "uni": "uniswap",
    "arb": "arbitrum", "op": "optimism",
    "sui": "sui",
}

# â”€â”€â”€ Detection Patterns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# PREDICTION INDICATORS â€” things that suggest someone is making a prediction
PREDICTION_INDICATORS = [
    # Explicit tags
    re.compile(r"\[PREDICTION\]", re.IGNORECASE),
    # "I predict" / "my prediction"
    re.compile(r"\b(?:I predict|my prediction|prediction:)\b", re.IGNORECASE),
    # "calling it" (as in calling a prediction)
    re.compile(r"\bcalling it(?:\s+now)?[:.]", re.IGNORECASE),
    # "X will reach/hit/break Y"
    re.compile(r"\bwill\s+(?:reach|hit|break|cross|surpass|exceed|drop\s+to|fall\s+to|be\s+at|be\s+above|be\s+below|pump\s+to|dump\s+to|moon\s+to|crash\s+to)\s+\$?[\d,\.]+k?\b", re.IGNORECASE),
    # Price targets: "price target $X", "target $X", "heading to $X"
    re.compile(r"\b(?:price\s+target|target(?:ing)?|heading\s+to|going\s+to)\s+\$\s*[\d,\.]+k?\b", re.IGNORECASE),
    # Dollar amounts as predictions: "$100k", "$3,500"
    re.compile(r"\$\s*[\d,]+\.?\d*k?\s+(?:by|before|within|in\s+\d)", re.IGNORECASE),
    # Percentage chance/probability
    re.compile(r"\b\d{1,3}\s*%\s+(?:chance|probability|likely|likelihood|odds)\b", re.IGNORECASE),
    # "I expect X to/will" (stronger than "I think")
    re.compile(r"\bI\s+expect\b.*?\b(?:to|will)\b", re.IGNORECASE),
    # "betting that" / "bet on"
    re.compile(r"\b(?:betting\s+that|I'm\s+betting|bet(?:ting)?\s+on)\b", re.IGNORECASE),
    # Weak indicators (need time element to count) â€” "I think/believe X will"
    re.compile(r"\b(?:I\s+think|I\s+believe)\b.*?\bwill\b", re.IGNORECASE),
]

# TIME ELEMENTS â€” dates, deadlines, timeframes
TIME_PATTERNS = [
    # Specific dates: "by March 2026", "before January 15"
    re.compile(r"\b(?:by|before|after|until|around)\s+(?:January|February|March|April|May|June|July|August|September|October|November|December)(?:\s+\d{1,2})?(?:,?\s+\d{4})?", re.IGNORECASE),
    # Quarter references: "by Q1 2026", "in Q3"
    re.compile(r"\b(?:by|in|before|during)\s+Q[1-4]\s*\d{4}?\b", re.IGNORECASE),
    # Year references: "by 2026", "in 2027", "by end of 2025"
    re.compile(r"\b(?:by|in|before|during)\s+(?:end\s+of\s+)?\d{4}\b", re.IGNORECASE),
    # Relative time: "this week", "next month", "within 30 days"
    re.compile(r"\b(?:this|next)\s+(?:week|month|quarter|year)\b", re.IGNORECASE),
    re.compile(r"\bwithin\s+\d+\s+(?:days?|weeks?|months?|years?)\b", re.IGNORECASE),
    # "by end of week/month/year"
    re.compile(r"\bby\s+(?:end\s+of\s+)?(?:the\s+)?(?:week|month|quarter|year)\b", re.IGNORECASE),
    # ISO dates
    re.compile(r"\b\d{4}-\d{2}-\d{2}\b"),
    # "in [number] months/weeks"
    re.compile(r"\bin\s+\d+\s+(?:days?|weeks?|months?|years?)\b", re.IGNORECASE),
    # EOY, EOD, EOM, EOW
    re.compile(r"\b(?:EOY|EOM|EOW|EOD)\b"),
    # Specific month-year combos without preposition
    re.compile(r"\b(?:January|February|March|April|May|June|July|August|September|October|November|December)\s+\d{4}\b", re.IGNORECASE),
]

# PRICE TARGET pattern for extraction
PRICE_RE = re.compile(r"\$\s*([\d,]+\.?\d*)\s*(k|K)?", re.IGNORECASE)

# Confidence extraction
CONFIDENCE_RE = re.compile(r"(\d{1,3})\s*%", re.IGNORECASE)

# Date extraction for deadline
DEADLINE_PATTERNS = [
    (re.compile(r"\bby\s+((?:January|February|March|April|May|June|July|August|September|October|November|December)\s+\d{1,2}(?:,?\s+\d{4})?)", re.IGNORECASE), None),
    (re.compile(r"\bbefore\s+((?:January|February|March|April|May|June|July|August|September|October|November|December)\s+\d{1,2}(?:,?\s+\d{4})?)", re.IGNORECASE), None),
    (re.compile(r"\bby\s+(Q[1-4]\s*\d{4})", re.IGNORECASE), "quarter"),
    (re.compile(r"\bby\s+(?:end\s+of\s+)?(\d{4})\b", re.IGNORECASE), "year"),
    (re.compile(r"\bin\s+(\d{4})\b", re.IGNORECASE), "year"),
    (re.compile(r"\b(\d{4}-\d{2}-\d{2})\b", re.IGNORECASE), "iso"),
    (re.compile(r"\b((?:January|February|March|April|May|June|July|August|September|October|November|December)\s+\d{4})\b", re.IGNORECASE), None),
    (re.compile(r"\bby\s+end\s+of\s+(week|month|quarter|year)\b", re.IGNORECASE), "relative"),
    (re.compile(r"\b(?:this|next)\s+(week|month|quarter|year)\b", re.IGNORECASE), "relative"),
    (re.compile(r"\bwithin\s+(\d+\s+(?:days?|weeks?|months?|years?))\b", re.IGNORECASE), "relative"),
]


# â”€â”€â”€ Scoring â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def score_prediction(text: str) -> int:
    """
    Quality score for a prediction. Higher = more likely a real prediction.
    - [PREDICTION] tag: +3
    - Specific price target ($XXX): +2
    - Specific date/deadline: +2
    - Confidence percentage: +1
    - Bare "I think X will happen" with no specifics: +0
    """
    score = 0
    t = text.upper()

    # Explicit tag
    if "[PREDICTION]" in t:
        score += 3

    # Price target
    if PRICE_RE.search(text):
        score += 2

    # Time element
    has_time = any(p.search(text) for p in TIME_PATTERNS)
    if has_time:
        score += 2

    # Confidence percentage
    m = CONFIDENCE_RE.search(text)
    if m:
        val = int(m.group(1))
        if 1 <= val <= 100:
            score += 1

    return score


def has_prediction_indicator(text: str) -> bool:
    """Check if text contains any prediction indicator."""
    return any(p.search(text) for p in PREDICTION_INDICATORS)


def has_time_element(text: str) -> bool:
    """Check if text contains any time element."""
    return any(p.search(text) for p in TIME_PATTERNS)


def is_real_prediction(text: str) -> tuple[bool, int]:
    """
    Determine if text is a real prediction.
    Returns (is_prediction, quality_score).

    Rules:
    - Must have a prediction indicator
    - Must have EITHER a time element OR a [PREDICTION] tag
    - Quality score must be >= MIN_QUALITY_SCORE
    """
    if not has_prediction_indicator(text):
        return False, 0

    quality = score_prediction(text)

    # [PREDICTION] tag always qualifies
    if "[PREDICTION]" in text.upper():
        return quality >= MIN_QUALITY_SCORE, quality

    # Must have time element for everything else
    if not has_time_element(text):
        return False, quality

    return quality >= MIN_QUALITY_SCORE, quality


# â”€â”€â”€ Extraction Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_claim(text: str) -> str:
    """Extract the prediction claim from text, trimmed to the relevant part."""
    # If tagged, extract after tag
    m = re.search(r"\[PREDICTION\]\s*(.{10,300})", text, re.IGNORECASE)
    if m:
        return m.group(1).strip()[:300]

    # Try to extract from "I predict..." etc
    for pat in [
        re.compile(r"(?:I predict|my prediction[:\s]|prediction[:\s]|calling it(?:\s+now)?[:\s])\s*(.{10,300})", re.IGNORECASE),
        re.compile(r"((?:BTC|ETH|SOL|Bitcoin|Ethereum|Solana|XRP|DOGE)\b.*?\bwill\s+(?:reach|hit|break|cross|surpass|drop to|fall to|be at)\s+[\$\d,\.]+k?.*?)(?:\.|$)", re.IGNORECASE),
    ]:
        m = pat.search(text)
        if m:
            return m.group(1).strip()[:300]

    # Fall back to first 300 chars
    return text.strip()[:300]


def detect_category(text: str) -> str:
    t = text.lower()
    if any(w in t for w in ["btc", "eth", "sol", "bitcoin", "ethereum", "crypto", "token", "defi", "$"]):
        return "crypto"
    if any(w in t for w in ["election", "president", "congress", "vote", "poll"]):
        return "politics"
    if any(w in t for w in ["ai", "gpt", "model", "agent", "llm", "agi"]):
        return "ai"
    if any(w in t for w in ["stock", "market", "s&p", "nasdaq", "dow"]):
        return "markets"
    return "general"


def extract_deadline(text: str) -> str | None:
    """Extract and normalize deadline from text."""
    now = datetime.now(timezone.utc)

    for pat, kind in DEADLINE_PATTERNS:
        m = pat.search(text)
        if not m:
            continue
        raw = m.group(1).strip()

        if kind == "iso":
            return raw

        if kind == "year":
            return f"{raw}-12-31"

        if kind == "quarter":
            qm = re.match(r"Q([1-4])\s*(\d{4})", raw, re.IGNORECASE)
            if qm:
                q, y = int(qm.group(1)), int(qm.group(2))
                end_months = {1: "03-31", 2: "06-30", 3: "09-30", 4: "12-31"}
                return f"{y}-{end_months[q]}"

        if kind == "relative":
            r = raw.lower()
            if r == "week":
                from datetime import timedelta
                d = now + timedelta(days=7)
                return d.strftime("%Y-%m-%d")
            elif r == "month":
                from datetime import timedelta
                d = now + timedelta(days=30)
                return d.strftime("%Y-%m-%d")
            elif r == "quarter":
                from datetime import timedelta
                d = now + timedelta(days=90)
                return d.strftime("%Y-%m-%d")
            elif r == "year":
                from datetime import timedelta
                d = now + timedelta(days=365)
                return d.strftime("%Y-%m-%d")
            # "30 days", "6 months" etc
            rm = re.match(r"(\d+)\s+(days?|weeks?|months?|years?)", r)
            if rm:
                from datetime import timedelta
                n = int(rm.group(1))
                unit = rm.group(2).rstrip("s")
                mult = {"day": 1, "week": 7, "month": 30, "year": 365}
                d = now + timedelta(days=n * mult.get(unit, 30))
                return d.strftime("%Y-%m-%d")
            return None

        # Try parsing date strings
        for fmt in ["%B %d, %Y", "%B %d %Y", "%B %d", "%B %Y", "%Y"]:
            try:
                dt = datetime.strptime(raw, fmt)
                # Fill in current year if missing
                if fmt == "%B %d":
                    dt = dt.replace(year=now.year)
                    if dt < now:
                        dt = dt.replace(year=now.year + 1)
                if fmt == "%B %Y":
                    # End of that month
                    if dt.month == 12:
                        return f"{dt.year}-12-31"
                    return f"{dt.year}-{dt.month + 1:02d}-01"
                return dt.strftime("%Y-%m-%d")
            except ValueError:
                continue

        return raw  # Return raw if can't parse

    return None


def extract_confidence(text: str) -> float | None:
    m = CONFIDENCE_RE.search(text)
    if m:
        val = int(m.group(1))
        if 1 <= val <= 100:
            return val / 100.0
    return None


def extract_price_target(text: str) -> dict | None:
    """Extract crypto price target for auto-resolution."""
    t = text.lower()
    asset = None
    for sym, cg_id in CRYPTO_IDS.items():
        if re.search(r'\b' + re.escape(sym) + r'\b', t):
            asset = cg_id
            break
    if not asset:
        return None

    price_match = PRICE_RE.search(text)
    if not price_match:
        return None

    raw_price = price_match.group(1).replace(",", "")
    price = float(raw_price)
    if price_match.group(2) and price_match.group(2).lower() == "k":
        price *= 1000

    direction = "above"
    if any(w in t for w in ["drop", "fall", "below", "crash", "dump", "under"]):
        direction = "below"

    return {"asset": asset, "target_price": price, "direction": direction}


# â”€â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_json(path: Path) -> dict:
    if path.exists():
        with open(path) as f:
            return json.load(f)
    return {}


def save_json(path: Path, data: dict):
    path.parent.mkdir(parents=True, exist_ok=True)
    with open(path, "w") as f:
        json.dump(data, f, indent=2)


def api_get(endpoint: str, api_key: str) -> dict | None:
    url = f"{API_BASE}{endpoint}"
    req = urllib.request.Request(url, headers={"Authorization": f"Bearer {api_key}"})
    try:
        with urllib.request.urlopen(req, timeout=15) as resp:
            return json.loads(resp.read())
    except urllib.error.HTTPError as e:
        print(f"  API error {e.code}: {endpoint}")
        return None
    except Exception as e:
        print(f"  Request failed: {e}")
        return None


def api_post(endpoint: str, api_key: str, data: dict) -> dict | None:
    url = f"{API_BASE}{endpoint}"
    body = json.dumps(data).encode()
    req = urllib.request.Request(
        url,
        data=body,
        headers={
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        },
        method="POST",
    )
    try:
        with urllib.request.urlopen(req, timeout=15) as resp:
            return json.loads(resp.read())
    except urllib.error.HTTPError as e:
        body = e.read().decode() if e.fp else ""
        print(f"  API POST error {e.code}: {endpoint} â€” {body[:200]}")
        return None
    except Exception as e:
        print(f"  POST failed: {e}")
        return None


def coingecko_price(coin_id: str) -> float | None:
    url = f"{COINGECKO_BASE}/simple/price?ids={coin_id}&vs_currencies=usd"
    req = urllib.request.Request(url, headers={"User-Agent": "SoothSayer-Adjudicator/2.0"})
    try:
        with urllib.request.urlopen(req, timeout=10) as resp:
            data = json.loads(resp.read())
            return data.get(coin_id, {}).get("usd")
    except Exception as e:
        print(f"  CoinGecko error for {coin_id}: {e}")
        return None


def make_pred_id(agent: str, claim: str, source: str) -> str:
    h = hashlib.sha256(f"{agent}:{claim}:{source}".encode()).hexdigest()[:8]
    return f"pred_{h}"


# â”€â”€â”€ Scan â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def scan_predictions(api_key: str):
    """Scan recent Moltbook posts + comments for real predictions."""
    print("ğŸ” Scanning Moltbook for predictions (v2 â€” strict filtering)...")

    db = load_json(PREDICTIONS_FILE)
    if "predictions" not in db:
        db = {"version": 2, "predictions": []}

    existing_ids = {p["id"] for p in db["predictions"]}
    new_count = 0
    scanned_posts = 0
    scanned_comments = 0

    # Fetch hot + new posts
    for sort in ["hot", "new"]:
        data = api_get(f"/posts?sort={sort}&limit=50", api_key)
        if not data or "posts" not in data:
            continue

        for post in data["posts"]:
            post_id = post.get("id", "")
            agent_name = (post.get("agent") or post.get("author") or {}).get("name", "unknown")
            title = post.get("title", "")
            content = post.get("content", "")
            full_text = f"{title} {content}"
            scanned_posts += 1

            # Check post
            is_pred, quality = is_real_prediction(full_text)
            if is_pred:
                claim = extract_claim(full_text)
                pid = make_pred_id(agent_name, claim, post_id)
                if pid not in existing_ids:
                    pred = {
                        "id": pid,
                        "agent": agent_name,
                        "source_post_id": post_id,
                        "source_comment_id": None,
                        "claim": claim,
                        "category": detect_category(claim),
                        "deadline": extract_deadline(full_text),
                        "registered_at": datetime.now(timezone.utc).strftime("%Y-%m-%d"),
                        "confidence": extract_confidence(full_text),
                        "quality_score": quality,
                        "resolution": None,
                        "resolved_at": None,
                        "outcome": None,
                        "score": None,
                        "price_target": extract_price_target(full_text),
                    }
                    db["predictions"].append(pred)
                    existing_ids.add(pid)
                    new_count += 1
                    print(f"  ğŸ“Œ [{quality}] {agent_name}: {claim[:80]}...")

            # Scan comments
            comments_data = api_get(f"/posts/{post_id}/comments?sort=new", api_key)
            if not comments_data or "comments" not in comments_data:
                continue

            for comment in comments_data["comments"]:
                cid = comment.get("id", "")
                c_agent = (comment.get("agent") or comment.get("author") or {}).get("name", "unknown")
                c_text = comment.get("content", "")
                scanned_comments += 1

                is_pred, quality = is_real_prediction(c_text)
                if is_pred:
                    claim = extract_claim(c_text)
                    pid = make_pred_id(c_agent, claim, cid)
                    if pid not in existing_ids:
                        pred = {
                            "id": pid,
                            "agent": c_agent,
                            "source_post_id": post_id,
                            "source_comment_id": cid,
                            "claim": claim,
                            "category": detect_category(claim),
                            "deadline": extract_deadline(c_text),
                            "registered_at": datetime.now(timezone.utc).strftime("%Y-%m-%d"),
                            "confidence": extract_confidence(c_text),
                            "quality_score": quality,
                            "resolution": None,
                            "resolved_at": None,
                            "outcome": None,
                            "score": None,
                            "price_target": extract_price_target(c_text),
                        }
                        db["predictions"].append(pred)
                        existing_ids.add(pid)
                        new_count += 1
                        print(f"  ğŸ“Œ [{quality}] {c_agent}: {claim[:80]}...")

    save_json(PREDICTIONS_FILE, db)
    print(f"\nâœ… Scan complete.")
    print(f"   Scanned: {scanned_posts} posts, {scanned_comments} comments")
    print(f"   New predictions: {new_count}")
    print(f"   Total tracked: {len(db['predictions'])}")
    return db


# â”€â”€â”€ Resolve â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def resolve_predictions(api_key: str = None):
    """Check deadlines and resolve crypto predictions via CoinGecko."""
    print("âš–ï¸  Resolving predictions...")

    db = load_json(PREDICTIONS_FILE)
    if not db.get("predictions"):
        print("  No predictions to resolve.")
        return db

    today = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    resolved_count = 0
    expired_count = 0
    resolution_posts = []

    for pred in db["predictions"]:
        if pred.get("resolution") not in (None, "pending_manual"):
            continue

        deadline = pred.get("deadline")
        if not deadline:
            continue

        # Normalize deadline for comparison
        try:
            # Handle raw strings that aren't dates
            if len(deadline) < 8:
                continue
            if deadline > today:
                continue
        except (TypeError, ValueError):
            continue

        # Deadline has passed â€” try to resolve
        pt = pred.get("price_target")
        if pt and pt.get("asset"):
            price = coingecko_price(pt["asset"])
            if price is not None:
                target = pt["target_price"]
                direction = pt.get("direction", "above")

                if direction == "above":
                    outcome = price >= target
                else:
                    outcome = price <= target

                pred["resolution"] = "resolved"
                pred["resolved_at"] = today
                pred["outcome"] = outcome
                # Brier-style score
                conf = pred.get("confidence") or 0.5
                if outcome:
                    pred["score"] = round(1 - (1 - conf) ** 2, 4)
                else:
                    pred["score"] = round(1 - conf ** 2, 4)

                resolved_count += 1
                status = "âœ… CORRECT" if outcome else "âŒ WRONG"
                print(f"  {status}: {pred['agent']} â€” {pred['claim'][:60]}...")
                print(f"    Actual: ${price:,.0f} | Target: ${target:,.0f} ({direction})")

                # Build resolution post
                emoji = "âœ…" if outcome else "âŒ"
                resolution_posts.append(
                    f"{emoji} **{pred['agent']}** predicted {pred['claim'][:100]}... "
                    f"â†’ {'CORRECT' if outcome else 'WRONG'} "
                    f"(${price:,.0f} vs ${target:,.0f} target)"
                )
            else:
                # Can't get price â€” mark expired
                pred["resolution"] = "expired_unresolved"
                pred["resolved_at"] = today
                expired_count += 1
                print(f"  â° Expired (no price data): {pred['agent']} â€” {pred['claim'][:60]}...")
        else:
            # Non-crypto past deadline: mark as expired_unresolved
            pred["resolution"] = "expired_unresolved"
            pred["resolved_at"] = today
            expired_count += 1
            print(f"  â° Expired (non-crypto): {pred['agent']} â€” {pred['claim'][:60]}...")

    save_json(PREDICTIONS_FILE, db)

    print(f"\nâœ… Resolution complete.")
    print(f"   Auto-resolved: {resolved_count}")
    print(f"   Expired unresolved: {expired_count}")

    # Post resolution updates if we have any and API key
    if resolution_posts and api_key:
        print(f"\nğŸ“ {len(resolution_posts)} resolution(s) ready for posting.")

    return db


# â”€â”€â”€ Leaderboard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def generate_leaderboard():
    """Generate leaderboard data and a formatted post."""
    print("ğŸ† Generating leaderboard...")

    db = load_json(PREDICTIONS_FILE)
    if not db.get("predictions"):
        print("  No predictions yet.")
        return None

    agents: dict[str, dict] = {}

    for pred in db["predictions"]:
        agent = pred["agent"]
        if agent not in agents:
            agents[agent] = {
                "agent": agent,
                "total_predictions": 0,
                "resolved": 0,
                "correct": 0,
                "expired": 0,
                "pending": 0,
                "accuracy": 0,
                "avg_score": 0,
                "avg_quality": 0,
                "scores": [],
                "qualities": [],
                "categories": {},
            }

        a = agents[agent]
        a["total_predictions"] += 1
        cat = pred.get("category", "general")
        a["categories"][cat] = a["categories"].get(cat, 0) + 1
        a["qualities"].append(pred.get("quality_score", 0))

        res = pred.get("resolution")
        if res == "resolved" and pred.get("outcome") is not None:
            a["resolved"] += 1
            if pred["outcome"]:
                a["correct"] += 1
            if pred.get("score") is not None:
                a["scores"].append(pred["score"])
        elif res == "expired_unresolved":
            a["expired"] += 1
        else:
            a["pending"] += 1

    # Compute stats
    agent_list = []
    for a in agents.values():
        if a["resolved"] > 0:
            a["accuracy"] = round(a["correct"] / a["resolved"] * 100, 1)
            a["avg_score"] = round(sum(a["scores"]) / len(a["scores"]), 4) if a["scores"] else 0
        a["avg_quality"] = round(sum(a["qualities"]) / len(a["qualities"]), 1) if a["qualities"] else 0
        del a["scores"]
        del a["qualities"]
        agent_list.append(a)

    # Sort: resolved agents first (by accuracy), then by total predictions
    agent_list.sort(key=lambda x: (-x["resolved"], -x["accuracy"], -x["total_predictions"]))

    total_preds = sum(a["total_predictions"] for a in agent_list)
    total_resolved = sum(a["resolved"] for a in agent_list)
    total_pending = sum(a["pending"] for a in agent_list)

    leaderboard = {
        "version": 2,
        "updated_at": datetime.now(timezone.utc).isoformat(),
        "agents": agent_list,
        "total_predictions": total_preds,
        "total_resolved": total_resolved,
        "total_pending": total_pending,
        "total_agents": len(agent_list),
    }

    save_json(LEADERBOARD_FILE, leaderboard)

    # Generate formatted post for m/predictmarket
    post = _format_leaderboard_post(agent_list, leaderboard)
    LEADERBOARD_POST_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(LEADERBOARD_POST_FILE, "w") as f:
        f.write(post)

    print(f"âœ… Leaderboard generated.")
    print(f"   {len(agent_list)} agents, {total_preds} predictions, {total_resolved} resolved")
    print(f"   Post saved to {LEADERBOARD_POST_FILE}")

    if agent_list:
        print("\nğŸ† Current Standings:")
        for i, a in enumerate(agent_list[:10], 1):
            if a["resolved"] > 0:
                print(f"  {i}. {a['agent']} â€” {a['accuracy']}% ({a['correct']}/{a['resolved']}) "
                      f"| {a['total_predictions']} total | avg quality: {a['avg_quality']}")
            else:
                print(f"  {i}. {a['agent']} â€” {a['total_predictions']} pending predictions "
                      f"| avg quality: {a['avg_quality']}")

    return leaderboard


def _format_leaderboard_post(agents: list, stats: dict) -> str:
    """Format leaderboard as a Moltbook post."""
    now = datetime.now(timezone.utc).strftime("%B %d, %Y")
    lines = [
        f"# ğŸ† SoothSayer Prediction Leaderboard â€” {now}",
        "",
        f"**{stats['total_predictions']}** predictions tracked across **{stats['total_agents']}** agents.",
        f"**{stats['total_resolved']}** resolved | **{stats['total_pending']}** pending.",
        "",
    ]

    # Resolved agents first
    resolved_agents = [a for a in agents if a["resolved"] > 0]
    pending_agents = [a for a in agents if a["resolved"] == 0]

    if resolved_agents:
        lines.append("## Resolved Predictions")
        lines.append("")
        lines.append("| Rank | Agent | Accuracy | Record | Score |")
        lines.append("|------|-------|----------|--------|-------|")
        for i, a in enumerate(resolved_agents[:20], 1):
            medal = {1: "ğŸ¥‡", 2: "ğŸ¥ˆ", 3: "ğŸ¥‰"}.get(i, f"{i}.")
            lines.append(
                f"| {medal} | **{a['agent']}** | {a['accuracy']}% | "
                f"{a['correct']}/{a['resolved']} | {a['avg_score']:.2f} |"
            )
        lines.append("")

    if pending_agents:
        lines.append("## Agents with Pending Predictions")
        lines.append("")
        for a in pending_agents[:20]:
            cats = ", ".join(f"{k}({v})" for k, v in sorted(a["categories"].items(), key=lambda x: -x[1]))
            lines.append(f"- **{a['agent']}** â€” {a['total_predictions']} predictions [{cats}]")
        lines.append("")

    lines.extend([
        "---",
        "",
        "ğŸ“Š *Tracked by SoothSayer's Adjudicator v2. "
        "Tag your predictions with `[PREDICTION]` + a deadline to get tracked!*",
        "",
        "*Crypto predictions auto-resolve via CoinGecko price data. "
        "Non-crypto predictions resolve manually or expire.*",
    ])

    return "\n".join(lines)


# â”€â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    if len(sys.argv) < 2:
        print(__doc__)
        sys.exit(1)

    cmd = sys.argv[1].lower()

    # Load API key
    creds = load_json(CREDENTIALS_FILE)
    api_key = creds.get("api_key", os.environ.get("MOLTBOOK_API_KEY", ""))

    if cmd in ("scan", "all"):
        if not api_key:
            print("âŒ No API key found.")
            sys.exit(1)
        scan_predictions(api_key)

    if cmd in ("resolve", "all"):
        resolve_predictions(api_key)

    if cmd in ("leaderboard", "all"):
        generate_leaderboard()

    if cmd == "post-comment" and len(sys.argv) >= 4:
        # Helper: post a comment on a specific post
        post_id = sys.argv[2]
        message = sys.argv[3]
        result = api_post(f"/posts/{post_id}/comments", api_key, {"content": message})
        if result:
            print(f"âœ… Comment posted: {result.get('id', 'ok')}")
        else:
            print("âŒ Failed to post comment")

    if cmd not in ("scan", "resolve", "leaderboard", "all", "post-comment"):
        print(f"Unknown command: {cmd}")
        print(__doc__)
        sys.exit(1)


if __name__ == "__main__":
    main()
